\documentclass[conference]{IEEEtran}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{xcolor}
\usepackage{multirow}

\title{Conformal Prediction for Reliable Handover in 5G Networks}

\author{
\IEEEauthorblockN{Johan Eliasson}
\IEEEauthorblockA{\url{https://github.com/elitan}}
}

\begin{document}
\maketitle

\begin{abstract}
Machine learning enables predictive handover in 5G networks, but lacks reliability guarantees. We apply conformal prediction (CP) to handover target prediction, providing the first formal coverage guarantees for this problem. Given a target coverage rate (e.g., 90\%), CP outputs a \emph{prediction set} of candidate cells guaranteed to contain the optimal target with high probability. We evaluate on synthetic scenarios with varying difficulty and real-world 5G traces. Key findings: (1)~CP adapts set size to prediction uncertainty---easy scenarios need 1.4 cells on average, hard scenarios need 4.7; (2)~standard CP exhibits conditional coverage gaps across UE speed groups; (3)~group-conditional CP closes these gaps; (4)~Adaptive Conformal Inference maintains coverage over time despite temporal dependencies. Results show CP provides valuable uncertainty quantification for handover, enabling adaptive protocols that trust ML when confident and fall back to measurement-based handover when uncertain.
\end{abstract}

\section{Introduction}

Fifth-generation networks employ dense deployments with advanced beamforming, creating challenges for mobility management~\cite{rappaport2013}. Handover---reassigning a user equipment (UE) session from one cell to another---must balance latency (predictive handover) against reliability (measurement-based handover)~\cite{3gpp38214}.

Machine learning enables predictive handover by forecasting the optimal target cell from current measurements~\cite{yajnanarayana2020}. However, ML-based predictions lack reliability guarantees: when should the network trust the ML prediction versus falling back to exhaustive measurement?

Conformal prediction (CP) addresses this gap by providing distribution-free coverage guarantees~\cite{vovk2005,angelopoulos2021}. Recent work applies CP to beam selection~\cite{hegde2024,deng2025} and channel prediction~\cite{cohen2022}, but \emph{not to handover target prediction}.

\textbf{Contributions.} We provide the first application of CP to handover:
\begin{enumerate}
    \item \textbf{CP for handover prediction.} We formulate handover target prediction as a classification problem and apply split conformal prediction to generate prediction sets with coverage guarantees.
    \item \textbf{Adaptive Conformal Inference.} We apply ACI~\cite{gibbs2021} to handle temporal dependencies in mobility data.
    \item \textbf{Conditional coverage analysis.} We expose coverage gaps across UE speed groups and close them with group-conditional CP~\cite{romano2020}.
    \item \textbf{Evaluation on synthetic and real data.} We evaluate on three synthetic scenarios and real-world Irish 5G traces.
\end{enumerate}

\section{Related Work}

\textbf{ML for handover.} Deep learning predicts handover targets from UE measurements~\cite{lee2020}. Reinforcement learning optimizes handover policies using contextual bandits~\cite{yajnanarayana2020}. These methods lack uncertainty quantification.

\textbf{CP for wireless.} Cohen et al.~\cite{cohen2022} apply CP to demodulation, modulation classification, and channel prediction. Hegde et al.~\cite{hegde2024} apply CP to beam selection in D-MIMO; Deng et al.~\cite{deng2025} use conformal risk control for near-field beam selection. Neither addresses handover or mobility.

\textbf{Our contribution.} We are the first to apply CP to handover target prediction, addressing temporal dependencies with ACI and conditional coverage gaps with group-conditional CP.

\section{System Model}

\subsection{Handover Prediction Problem}

Consider a cellular network with $K$ cells. At time $t$, UE has serving cell $c_t$ and measurements $\mathbf{x}_t$ (RSRP, speed, etc.). The goal is to predict the optimal target cell $y_t \in \{1, \ldots, K\}$ for handover.

A predictor $\hat{f}$ outputs class probabilities $\hat{p}(y|\mathbf{x}_t)$. Standard prediction selects $\hat{y} = \arg\max_y \hat{p}(y|\mathbf{x}_t)$.

\subsection{Conformal Prediction}

Split CP~\cite{vovk2005} uses a calibration set to compute a threshold $\hat{q}$ such that the prediction set
\begin{equation}
    \mathcal{C}(\mathbf{x}) = \{y : \hat{p}(y|\mathbf{x}) \geq 1 - \hat{q}\}
\end{equation}
satisfies $\Pr[y^* \in \mathcal{C}(\mathbf{x})] \geq 1 - \alpha$ for target miscoverage $\alpha$.

\subsection{Adaptive Protocol}

\begin{algorithm}
\caption{Adaptive Handover Management}
\begin{algorithmic}[1]
\REQUIRE Measurements $\mathbf{x}$, threshold $K_{\max}$, calibrated model
\STATE $\mathcal{C}(\mathbf{x}) \leftarrow$ conformal prediction set
\IF{$|\mathcal{C}(\mathbf{x})| \leq K_{\max}$}
    \STATE Predictive handover to cells in $\mathcal{C}(\mathbf{x})$
\ELSE
    \STATE Measurement-based handover (exhaustive)
\ENDIF
\end{algorithmic}
\end{algorithm}

\section{Methods}

\subsection{Group-Conditional CP}

Standard CP provides marginal coverage but may undercover subpopulations. We partition by UE speed quartile and calibrate per-group thresholds~\cite{romano2020}.

\subsection{Adaptive Conformal Inference}

Handover data is temporal, violating exchangeability. ACI~\cite{gibbs2021} adapts the threshold online:
\begin{equation}
    \alpha_{t+1} = \alpha_t + \gamma(\alpha - \text{err}_t)
\end{equation}
where $\text{err}_t = \mathbf{1}[y_t \notin \mathcal{C}(\mathbf{x}_t)]$.

\section{Experimental Setup}

\subsection{Synthetic Scenarios}

We generate three scenarios with increasing difficulty:
\begin{itemize}
    \item \textbf{Easy:} 9 cells, low noise, 5-step prediction
    \item \textbf{Medium:} 16 cells, moderate noise, 10-step prediction
    \item \textbf{Hard:} 25 cells, high noise, 15-step prediction
\end{itemize}

\subsection{Real-World Data}

We use the Irish 5G dataset~\cite{irish5g}: 82K samples from 50 driving traces, 133 cells, 2\% handover rate.

\section{Results}

\subsection{Synthetic Scenarios}

Table~\ref{tab:main} compares Top-K baselines with conformal prediction across three scenarios of increasing difficulty.

\begin{table}[t]
\caption{CP Results ($\alpha=0.1$, mean $\pm$ std over 5 seeds)}
\label{tab:main}
\centering
\begin{tabular}{llcc}
\toprule
Scenario & Method & Coverage & Avg Size \\
\midrule
\multirow{4}{*}{Easy (9 cells)}
  & Top-1 & $.798 \pm .015$ & 1.00 \\
  & Top-3 & $.976 \pm .002$ & 3.00 \\
  & Standard CP & $.899 \pm .012$ & $1.36 \pm .05$ \\
  & ACI & $.901 \pm .001$ & $1.40 \pm .06$ \\
\midrule
\multirow{4}{*}{Medium (16 cells)}
  & Top-1 & $.654 \pm .019$ & 1.00 \\
  & Top-3 & $.903 \pm .008$ & 3.00 \\
  & Standard CP & $.894 \pm .010$ & $2.49 \pm .09$ \\
  & ACI & $.901 \pm .001$ & $2.56 \pm .17$ \\
\midrule
\multirow{4}{*}{Hard (25 cells)}
  & Top-1 & $.513 \pm .015$ & 1.00 \\
  & Top-3 & $.786 \pm .011$ & 3.00 \\
  & Standard CP & $.898 \pm .013$ & $4.75 \pm .20$ \\
  & ACI & $.900 \pm .000$ & $4.85 \pm .19$ \\
\bottomrule
\end{tabular}
\end{table}

The key finding is that \textbf{CP adapts set size to prediction difficulty}. In Easy (80\% base accuracy), CP needs only 1.36 cells on average. In Hard (51\% accuracy), CP requires 4.75 cells but guarantees $\sim$90\% coverage, while Top-3 achieves only 79\%.

\subsection{End-to-End Handover Performance}

\begin{table}[t]
\caption{End-to-End Handover Performance ($K_{\max}=5$)}
\label{tab:e2e}
\centering
\begin{tabular}{lccc}
\toprule
Scenario & HO Success & Meas. Overhead & RLF Rate \\
\midrule
Easy & $89.9\% \pm 1.2\%$ & $15.2\%$ & $10.1\%$ \\
Medium & $89.4\% \pm 1.0\%$ & $15.6\%$ & $10.6\%$ \\
Hard & $92.2\% \pm 1.5\%$ & $38.5\%$ & $7.8\%$ \\
\midrule
\multicolumn{4}{l}{\small Exhaustive: Success=100\%, Overhead=100\%} \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:e2e} shows end-to-end handover performance. With $K_{\max}=5$, CP enables \textbf{61--85\% measurement savings} compared to exhaustive search. The tradeoff is a 7--10\% radio link failure (RLF) rate---cases where CP was confident but wrong. This is the cost of undercoverage: when $y^* \notin \mathcal{C}(\mathbf{x})$ and $|\mathcal{C}(\mathbf{x})| \leq K_{\max}$, predictive handover fails.

\subsection{Conditional Coverage Analysis}

\begin{table}[t]
\caption{Conditional Coverage by UE Speed ($\alpha=0.1$)}
\label{tab:conditional}
\centering
\begin{tabular}{llcccc}
\toprule
 & & \multicolumn{4}{c}{Speed Quartile} \\
\cmidrule(lr){3-6}
Scenario & Method & Slow & Med-S & Med-F & Fast \\
\midrule
\multirow{2}{*}{Easy}
  & Std CP & 0.93 & 0.94 & 0.92 & 0.90 \\
  & GCP & 0.93 & 0.91 & 0.93 & 0.91 \\
\midrule
\multirow{2}{*}{Medium}
  & Std CP & 0.90 & 0.89 & 0.91 & 0.90 \\
  & GCP & 0.90 & 0.87 & 0.91 & 0.91 \\
\midrule
\multirow{2}{*}{Hard}
  & Std CP & 0.90 & \textbf{0.89} & 0.89 & \textbf{0.89} \\
  & GCP & 0.89 & 0.90 & 0.89 & 0.89 \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:conditional} reveals conditional coverage gaps. In the Hard scenario, standard CP undercovers Med-Slow and Fast UEs (88.9\% and 88.8\% vs.\ 90\% target). Group-conditional CP (GCP) partially closes these gaps, improving Med-Slow to 89.8\%.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/main_results_v3.png}
\caption{Results (5 seeds). (a) Standard CP and ACI hit 90\% target; RAPS overcoverts. (b) RAPS requires 3--6$\times$ larger sets. (c) End-to-end: 85--61\% measurement savings. (d) CP adapts while Top-K is fixed.}
\label{fig:main}
\end{figure}

\subsection{Adaptive Conformal Inference}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/aci_rolling.png}
\caption{ACI rolling coverage (window=200) maintains $\sim$90\% target across all scenarios despite temporal dependencies in mobility data.}
\label{fig:aci}
\end{figure}

Figure~\ref{fig:aci} shows ACI maintains coverage over time. The rolling coverage oscillates around the 90\% target, demonstrating that ACI successfully handles temporal dependencies in handover data.

\subsection{Real-World Validation}

We evaluate on the Irish 5G dataset~\cite{irish5g}: 82K samples from 50 driving traces across 133 cells.

\begin{table}[t]
\caption{Irish 5G Real-World Results}
\label{tab:irish}
\centering
\begin{tabular}{lcc}
\toprule
Method & Coverage & Avg Size \\
\midrule
Top-1 & 0.334 & 1 \\
Top-5 & 0.779 & 5 \\
Top-10 & 0.820 & 10 \\
\midrule
CP ($\alpha=0.05$) & 0.874 & 17.7 \\
CP ($\alpha=0.10$) & 0.785 & 4.6 \\
CP ($\alpha=0.20$) & 0.681 & 3.0 \\
\bottomrule
\end{tabular}
\end{table}

Real-world handover prediction is significantly harder than synthetic scenarios (Table~\ref{tab:irish}). With only serving cell measurements (no neighbor RSRP), Top-1 accuracy is just 33\%. CP with $\alpha=0.05$ achieves 87\% coverage but requires 17.7 cells on average. This highlights the need for richer input features (neighbor cell measurements) in practical deployments.

\section{Discussion}

\textbf{Why CP for handover?} The cost of undercoverage in handover is \emph{radio link failure} (RLF)---dropped calls, interrupted sessions, degraded user experience. CP provides formal guarantees: with $\alpha=0.10$, at most 10\% of handovers will fail due to the true target being outside the prediction set. This enables networks to make principled tradeoffs between latency (predictive handover) and reliability (exhaustive measurement).

\textbf{When does CP help?} CP provides value when prediction uncertainty varies. In easy scenarios, set size is near 1 (minimal overhead). In hard scenarios, larger sets are needed but provide reliability. The key insight is that CP \emph{adapts} to difficulty automatically.

\textbf{RAPS comparison.} Regularized Adaptive Prediction Sets (RAPS) achieves higher coverage (96--100\%) but requires 3--6$\times$ larger sets (8--14 cells vs.\ 1.4--4.8). For handover, overcoverage is wasteful---we want to \emph{hit} 90\%, not exceed it. Standard CP is preferred because it minimizes set size while meeting the coverage target.

\textbf{Real-world coverage gap.} Table~\ref{tab:irish} shows CP with $\alpha=0.10$ achieves only 78.5\% coverage, below the 90\% target. This occurs because the Irish dataset has limited features (only serving cell RSRP, no neighbor measurements) and 133 candidate cells. The underlying model has low confidence across most predictions, causing the calibrated threshold to be low. When deployed with richer features (neighbor RSRP, historical patterns), we expect tighter coverage.

\textbf{Group-conditional CP tradeoffs.} GCP does not universally improve coverage. In the Medium scenario, GCP undercovers Med-Slow UEs (87\% vs.\ 89\% for standard CP). This occurs when group sizes are small, leading to noisy threshold estimation. Practitioners should balance conditional fairness against sample efficiency.

\textbf{Practical deployment.} The adaptive protocol (Algorithm~1) enables networks to balance latency against reliability. When $|\mathcal{C}(\mathbf{x})| \leq K_{\max}$, the network can skip measurement reporting for cells outside the set. O-RAN's near-real-time RIC could host the CP calibration, updating thresholds as conditions change.

\textbf{Limitations.} (i) Synthetic data may not capture all real-world complexity. (ii) Real data lacks neighbor cell measurements, limiting predictor quality. (iii) Evaluation is offline; online deployment may face distribution shift.

\section{Conclusion}

We presented the first application of conformal prediction to handover target prediction. CP provides formal coverage guarantees, adapts set size to prediction difficulty, and enables adaptive protocols that balance predictive handover (low latency) against measurement-based fallback (high reliability). Key findings: (1)~CP adapts---easy scenarios need $\sim$1.4 cells, hard scenarios need $\sim$4.7; (2)~ACI maintains coverage despite temporal dependencies; (3)~group-conditional CP reduces coverage variance across UE speeds but requires sufficient group sizes. Future work includes online deployment with ACI threshold adaptation, integration with O-RAN near-RT RIC, and richer input features (neighbor RSRP, RIS measurements).

\bibliographystyle{IEEEtran}
\begin{thebibliography}{15}

\bibitem{rappaport2013}
T.~S.~Rappaport \emph{et al.}, ``Millimeter wave mobile communications for 5G cellular,'' \emph{IEEE Access}, 2013.

\bibitem{3gpp38214}
3GPP TS~38.214, ``NR; Physical layer procedures for data,'' 2022.

\bibitem{yajnanarayana2020}
V.~Yajnanarayana, H.~Ryd\'{e}n, and L.~H\'{e}vizi, ``5G handover using reinforcement learning,'' in \emph{Proc. IEEE 5GWF}, 2020.

\bibitem{vovk2005}
V.~Vovk, A.~Gammerman, and G.~Shafer, \emph{Algorithmic Learning in a Random World}. Springer, 2005.

\bibitem{angelopoulos2021}
A.~N.~Angelopoulos and S.~Bates, ``A gentle introduction to conformal prediction,'' \emph{arXiv:2107.07511}, 2021.

\bibitem{hegde2024}
D.~N.~Hegde \emph{et al.}, ``Reliable and efficient beam selection using conformal prediction in 6G systems,'' in \emph{Proc. IEEE WCM}, 2024.

\bibitem{deng2025}
J.~Deng \emph{et al.}, ``SCAN-BEST: Sub-6GHz-aided near-field beam selection with formal reliability guarantees,'' \emph{arXiv:2503.13801}, 2025.

\bibitem{cohen2022}
K.~M.~Cohen \emph{et al.}, ``Calibrating AI models for wireless communications via conformal prediction,'' \emph{IEEE TMLCN}, 2022.

\bibitem{gibbs2021}
I.~Gibbs and E.~Cand\`{e}s, ``Adaptive conformal inference under distribution shift,'' \emph{NeurIPS}, 2021.

\bibitem{romano2020}
Y.~Romano \emph{et al.}, ``With malice toward none: Assessing uncertainty via equalized coverage,'' \emph{HDSR}, 2020.

\bibitem{lee2020}
W.~Lee \emph{et al.}, ``Prediction-based conditional handover for 5G mm-wave networks,'' \emph{IEEE Access}, 2020.

\bibitem{irish5g}
D.~Raca \emph{et al.}, ``Beyond throughput: A 5G dataset with channel and context metrics,'' in \emph{Proc. MMSys}, 2020.

\end{thebibliography}

\end{document}
