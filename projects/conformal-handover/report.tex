\documentclass[conference]{IEEEtran}
\usepackage[top=0.75in, bottom=1in, left=0.625in, right=0.625in, columnsep=0.25in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{cite}
\usepackage[bookmarks=false,pdfborder={0 0 0},hypertexnames=false]{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}

\title{Conformal Prediction for Reliable Handover Under Distribution Shift}

\author{
\IEEEauthorblockN{Johan Eliasson Eklund}
\IEEEauthorblockA{\url{https://github.com/elitan}}
}

\begin{document}
\maketitle

\begin{abstract}
ML handover prediction is accurate in-distribution but fragile under shift. We evaluate conformal prediction (CP) for 5G handover under synthetic and real-world drift. We compare static CP, Adaptive Conformal Inference (ACI), weighted CP, and a confidence-gated triggered ACI against Top-$k$ and a 3dB hysteresis baseline. On in-distribution synthetic data, static CP reaches $90.4\%$ coverage with set size $2.46$. Under speed and noise shifts, weighted CP reaches $91.1\%$ in the speed-shift case. Under severe shadow shift, static CP drops to $69.1\%$ while ACI restores $88.7\%$ at larger sets (5.99). In regime-switch streams, ACI stabilizes rolling coverage near the 90\% target. ACI step-size sweep shows $\gamma=0.002$--$0.005$ gives the best reliability-overhead tradeoff in our setup. On Irish 5G driving traces with speed-split drift, static CP reaches $76.3\%$ coverage (size 4.69), weighted CP $74.7\%$ (size 4.37), and ACI $87.7\%$ (size 14.7). Results show reliability under shift needs adaptive conformal control, not static calibration alone.
\end{abstract}

\section{Introduction}

Predictive handover reduces latency but can fail badly when radio conditions shift. Traditional 3GPP handover logic relies on hysteresis events~\cite{3gpp38331,3gpp38214}. ML-based handover prediction improves point accuracy but provides no risk control when distribution changes~\cite{lee2020,yajnanarayana2020}. In production, that gap maps directly to radio link failure risk.

Conformal prediction (CP) gives finite-sample marginal coverage guarantees~\cite{vovk2005,angelopoulos2021}. Recent wireless CP work focuses on demodulation, channel tasks, and beam selection~\cite{cohen2022,hegde2024,deng2025}, while handover under distribution shift is still underexplored. This paper targets that gap.

\textbf{Contributions.}
\begin{enumerate}
    \item We benchmark handover reliability under four synthetic shifts plus a regime-switch stream.
    \item We compare static CP, ACI~\cite{gibbs2021}, and weighted CP under the same base predictor and KPI mapping.
    \item We validate on Irish 5G driving traces with source-target speed split.
    \item We provide budget-aware reproducible runs (local-first, capped overflow policy) and release all generated artifacts.
\end{enumerate}

\section{Related Work}

ML handover methods span supervised and reinforcement-learning policies~\cite{lee2020,yajnanarayana2020}. CP in wireless has shown value for calibration and reliability~\cite{cohen2022}. CP for beam selection shows strong reliability-efficiency tradeoffs~\cite{hegde2024,deng2025}. The missing piece is handover under shift: static calibration can fail as mobility, shadowing, and measurement noise drift over time.

\section{System and Methods}

\subsection{Handover Prediction Setup}

At time $t$, the model predicts future best cell $y_t=\arg\max_k \text{RSRP}_k(t+H)$ using input
\begin{equation}
\mathbf{x}_t=[\text{RSRP}_1,\ldots,\text{RSRP}_K,\mathbf{e}_{c_t},v_t].
\end{equation}
We use an MLP classifier and softmax scores $\hat p(y\mid\mathbf{x})$.

\subsection{Baselines and Conformal Variants}

\textbf{3dB baseline:} handover if best neighbor exceeds serving by 3dB.

\textbf{Static CP:}
\begin{equation}
\mathcal{C}(\mathbf{x})=\{y:\hat p(y\mid\mathbf{x})\ge 1-\hat q\},
\end{equation}
with $\hat q$ calibrated on held-out source calibration data.

\textbf{ACI:} online update of effective miscoverage level to track sequential drift~\cite{gibbs2021}.

\textbf{Weighted CP:} source calibration scores reweighted by estimated density ratio $w(\mathbf{x})\propto p_T(\mathbf{x})/p_S(\mathbf{x})$ using a source-vs-target logistic discriminator.

\textbf{Triggered ACI:} confidence-gated mixture that uses static CP on high-confidence samples and ACI sets on low-confidence samples (threshold from source calibration confidence quantile).

\subsection{System KPI Mapping}

Coverage maps to handover success with bounded miss risk. Set size maps to measurement overhead. Undercoverage maps to RLF proxy. Serving-cell retention in small sets acts as implicit hysteresis and affects ping-pong rate.

\section{Experimental Setup}

\subsection{Synthetic Shift Benchmark}

Source setting: medium scenario (4$\times$4 cells, $\sigma=6$ dB shadowing, measurement noise 4 dB, speed 1--30 m/s, horizon $H=10$). We train on source and calibrate on source only.

Target shifts:
\begin{enumerate}
    \item IID (same as source)
    \item Speed shift (20--50 m/s)
    \item Measurement-noise shift (8 dB)
    \item Shadow shift ($\sigma=10$ dB)
    \item Regime switch (source-like first half, harsh second half)
\end{enumerate}

Each result is mean$\pm$std across 5 seeds (42,123,456,789,1011), 600 trajectories/seed, 20 epochs.

\subsection{Real-World Drift Benchmark}

Dataset: Irish 5G driving traces~\cite{irish5g}. We split traces by average speed: lower-speed traces as source, higher-speed traces as target. Model trains and calibrates on source only, then evaluates on target.

\section{Results}

\subsection{Coverage Under Shift}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/shift-coverage-v6.pdf}
\caption{Coverage across synthetic shifts. Static CP degrades under hard shift, ACI is most robust, weighted CP helps in moderate covariate shift.}
\label{fig:shift-coverage}
\end{figure}

\begin{table}[t]
\caption{Synthetic Shift Coverage (mean $\pm$ std)}
\label{tab:shift-coverage}
\centering
\begin{tabular}{lccccc}
\toprule
Shift & 3dB & Top-1 & Top-3 & Static CP & ACI \\
\midrule
IID & $.64\pm.02$ & $.68\pm.02$ & $.91\pm.01$ & $.90\pm.01$ & $.90\pm.00$ \\
Speed & $.62\pm.01$ & $.65\pm.01$ & $.90\pm.01$ & $.90\pm.01$ & $.90\pm.00$ \\
MeasNoise & $.55\pm.02$ & $.64\pm.02$ & $.89\pm.01$ & $.88\pm.01$ & $.90\pm.00$ \\
Shadow & $.40\pm.01$ & $.44\pm.01$ & $.72\pm.01$ & $.69\pm.01$ & $.89\pm.00$ \\
Regime & $.49\pm.02$ & $.53\pm.02$ & $.79\pm.01$ & $.78\pm.01$ & $.89\pm.00$ \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:shift-coverage} shows the main trend: static CP is reliable near source but degrades under strong shift (shadow, regime). ACI keeps coverage close to target by expanding sets online.

\subsection{Tradeoff in Hard Shifts}

\begin{table}[t]
\caption{Hard-Shift KPI Tradeoff (mean over 5 seeds)}
\label{tab:hard-shift-kpi}
\centering
\begin{tabular}{llcccc}
\toprule
Shift & Method & Coverage & Set Size & RLF Proxy & Overhead \\
\midrule
\multirow{4}{*}{Shadow}
& Static CP & $.691$ & 2.62 & $.306$ & $.170$ \\
& ACI & $\mathbf{.887}$ & 5.99 & $\mathbf{.072}$ & $.599$ \\
& Triggered ACI & $.843$ & 5.39 & $.121$ & $.540$ \\
& Weighted CP & $.690$ & 2.60 & $.308$ & $.168$ \\
\midrule
\multirow{4}{*}{Regime}
& Static CP & $.782$ & 2.61 & $.216$ & $.167$ \\
& ACI & $\mathbf{.892}$ & 4.48 & $\mathbf{.083}$ & $.416$ \\
& Triggered ACI & $.870$ & 4.21 & $.108$ & $.387$ \\
& Weighted CP & $.790$ & 2.71 & $.207$ & $.176$ \\
\bottomrule
\end{tabular}
\end{table}

Paired seed deltas confirm hard-shift reliability gains: ACI vs static is $+19.6$pp coverage on shadow shift (95\% CI $[19.2,20.0]$) and $+11.0$pp on regime switch (95\% CI $[10.0,12.2]$). Triggered ACI keeps most of that gain ($+15.2$pp shadow, $+8.7$pp regime) while reducing overhead versus full ACI by $5.90$pp and $2.90$pp, respectively.

\subsection{Regime-Switch Stability}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/regime-switch-rolling-v6.pdf}
\caption{Rolling coverage in regime-switch stream (window=200). ACI tracks the 90\% target more closely than static and weighted CP.}
\label{fig:regime-rolling}
\end{figure}

In regime-switch streams, static and weighted thresholds lag after the phase boundary. ACI adapts online and recovers target-level coverage.

\subsection{ACI Step-Size Sensitivity}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/aci-gamma-ablation-v6.pdf}
\caption{Regime-switch ACI tradeoff over $\gamma$. Smaller $\gamma$ improves coverage but increases set size and overhead.}
\label{fig:aci-gamma}
\end{figure}

Figure~\ref{fig:aci-gamma} quantifies ACI sensitivity. In our regime-switch benchmark, small step sizes ($\gamma=0.002$--$0.005$) achieve the highest coverage ($\approx 89.6\%$) with moderate set inflation, while larger values ($\gamma=0.05$) reduce coverage to $87.3\%$ but lower overhead. This supports tuning $\gamma$ as a direct reliability-overhead control knob.

\subsection{Real-World Drift Results}

\begin{table}[t]
\caption{Irish 5G Speed-Split Drift Results}
\label{tab:irish-shift}
\centering
\begin{tabular}{lcc}
\toprule
Method & Coverage & Avg Size \\
\midrule
Top-1 & $.309$ & 1.00 \\
Top-3 & $.635$ & 3.00 \\
Static CP & $.763$ & 4.69 \\
ACI & $\mathbf{.877}$ & 14.67 \\
Triggered ACI & $.829$ & 10.03 \\
Weighted CP & $.747$ & 4.37 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/irish-shift-rolling-v6.pdf}
\caption{Irish drift rolling coverage (window=200). ACI is most stable under source-target speed split.}
\label{fig:irish-rolling}
\end{figure}

Real-world drift confirms the synthetic trend. Static calibration improves over Top-$k$, ACI provides the strongest reliability, and triggered ACI offers a lower-overhead middle point.

\section{Discussion}

\textbf{When to use which method.} Static CP is a strong default in stable conditions. Weighted CP helps moderate covariate shift when target feature support overlaps source. ACI is the robust choice for severe sequential drift, with $\gamma$ tuning used to set reliability-overhead preference. Triggered ACI is a middle point when overhead budget is tight.

\textbf{System implications.} Reliability gains translate to lower RLF proxy but require explicit overhead budgeting. A practical policy can use ACI in high-uncertainty periods and revert to static CP in stable periods.

\textbf{Limitations.} Synthetic channels still simplify real deployments. Irish traces have limited feature richness versus full network measurement reports. We evaluate offline; online deployment requires streaming integration and control-plane constraints.

\section{Conclusion}

We presented a shift-focused handover reliability study with conformal prediction. Static CP works well in-distribution but degrades in severe shift. ACI restores near-target coverage under shadow and regime-switch drift. Weighted CP improves moderate shifts with smaller set inflation than ACI. A confidence-gated triggered ACI recovers most hard-shift reliability gains with lower overhead than full ACI. On Irish real-world speed-split drift, ACI achieves the highest reliability. The core practical result is clear: robust handover reliability needs adaptive conformal control, not static calibration alone.

\appendices
\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}
\renewcommand{\theHtable}{A\arabic{table}}
\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}
\renewcommand{\theHfigure}{A\arabic{figure}}
\section{Appendix: Ensemble and Latency}

\begin{table}[t]
\caption{Appendix: CP vs Ensemble (from v5 runs, 5 seeds)}
\label{tab:appendix-ensemble}
\centering
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{CP (1 model)} & \multicolumn{2}{c}{Ensemble (5 models)} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
Scenario & Coverage & Size & Coverage & Size \\
\midrule
Easy & $.900$ & 1.37 & $.900$ & 1.38 \\
Medium & $.893$ & 2.47 & $.898$ & 2.57 \\
Hard & $.898$ & 4.80 & $.903$ & 5.05 \\
\bottomrule
\end{tabular}
\end{table}

Measured medium-scenario latency: calibration $0.08$ ms, CP set construction $1.59\,\mu$s/sample, NN inference $0.50\,\mu$s/sample.

\bibliographystyle{IEEEtran}
\begin{thebibliography}{15}

\bibitem{rappaport2013}
T.~S.~Rappaport \emph{et al.}, ``Millimeter wave mobile communications for 5G cellular,'' \emph{IEEE Access}, 2013.

\bibitem{3gpp38214}
3GPP TS~38.214, ``NR; Physical layer procedures for data,'' 2022.

\bibitem{3gpp38331}
3GPP TS~38.331, ``NR; Radio Resource Control (RRC); Protocol specification,'' 2022.

\bibitem{yajnanarayana2020}
V.~Yajnanarayana, H.~Ryd\'{e}n, and L.~H\'{e}vizi, ``5G handover using reinforcement learning,'' in \emph{Proc. IEEE 5GWF}, 2020.

\bibitem{vovk2005}
V.~Vovk, A.~Gammerman, and G.~Shafer, \emph{Algorithmic Learning in a Random World}. Springer, 2005.

\bibitem{angelopoulos2021}
A.~N.~Angelopoulos and S.~Bates, ``A gentle introduction to conformal prediction,'' \emph{arXiv:2107.07511}, 2021.

\bibitem{hegde2024}
D.~N.~Hegde \emph{et al.}, ``Reliable and efficient beam selection using conformal prediction in 6G systems,'' in \emph{Proc. IEEE WCM}, 2024.

\bibitem{deng2025}
J.~Deng \emph{et al.}, ``SCAN-BEST: Sub-6GHz-aided near-field beam selection with formal reliability guarantees,'' \emph{arXiv:2503.13801}, 2025.

\bibitem{cohen2022}
K.~M.~Cohen \emph{et al.}, ``Calibrating AI models for wireless communications via conformal prediction,'' \emph{IEEE TMLCN}, 2022.

\bibitem{gibbs2021}
I.~Gibbs and E.~Cand\`{e}s, ``Adaptive conformal inference under distribution shift,'' \emph{NeurIPS}, 2021.

\bibitem{romano2020}
Y.~Romano \emph{et al.}, ``With malice toward none: Assessing uncertainty via equalized coverage,'' \emph{HDSR}, 2020.

\bibitem{lee2020}
W.~Lee \emph{et al.}, ``Prediction-based conditional handover for 5G mm-wave networks,'' \emph{IEEE Access}, 2020.

\bibitem{irish5g}
D.~Raca \emph{et al.}, ``Beyond throughput: A 5G dataset with channel and context metrics,'' in \emph{Proc. MMSys}, 2020.

\bibitem{lakshminarayanan2017}
B.~Lakshminarayanan \emph{et al.}, ``Simple and scalable predictive uncertainty estimation using deep ensembles,'' in \emph{NeurIPS}, 2017.

\end{thebibliography}

\end{document}
